{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different Classifiers, Hyertuning Methods, and Speed on Diabetes Classification Dataset\n",
    "\n",
    "1. Linear Regression Classifer\n",
    "    1. Classification\n",
    "2. Random Forest Classifier\n",
    "    1. Classification\n",
    "    2. Feature Importance\n",
    "    3. Hyper-Parameter Tuning\n",
    "3. Support Vector Machine\n",
    "    1. Preprocesing\n",
    "    2. Classification\n",
    "    3. Hyper-Parameter Tuning\n",
    "    4. Cross-Validation Results\n",
    "4. Principal Component Analysis\n",
    "    1. Dimensionality reduction is an essential task in many data analysis exercises, and it involves projecting the data to a lower-dimensional space using Singular Value Decomposition. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# !{sys.executable} -m pip uninstall networkx\n",
    "# !{sys.executable} -m pip install pandas==1.1.0\n",
    "#!{sys.executable} -m pip install networkx==2.4\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "print(pd.__version__)\n",
    "import tests as tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \"\"\"\n",
    "    Class for the Data for the models\n",
    "    \"\"\"\n",
    "    def dataAllocation(self,path):\n",
    "        \n",
    "        \"\"\"\n",
    "        Separate out the x_data and y_data and return each\n",
    "        \n",
    "            args: string path for .csv file\n",
    "            \n",
    "            return: pandas dataframe, pandas dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        data = pd.read_csv(path)\n",
    "        x_data = data.loc[:,data.columns != \"y\"].to_numpy()\n",
    "        y_data = data.loc[:,\"y\"].to_numpy()\n",
    "        \n",
    "        return x_data,y_data\n",
    "    \n",
    "    def trainSets(self,x_data,y_data):\n",
    "        \"\"\"\n",
    "        Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test.\n",
    "        Use the train_test_split method in sklearn with the parameter 'shuffle' set to true and the 'random_state' set to 614.\n",
    "            \n",
    "            args: pandas dataframe, pandas dataframe\n",
    "            \n",
    "            return: pandas dataframe, pandas dataframe, pandas series, pandas series\n",
    "        \"\"\"\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.3, random_state = 614, shuffle=True)\n",
    "        y_train = pd.Series(y_train) \n",
    "        y_test = pd.Series(y_test) \n",
    "\n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel():\n",
    "    \"\"\"\n",
    "    Class for Linear Regression Model\n",
    "    \"\"\"\n",
    "    def linearClassifer(self,x_train, x_test, y_train):\n",
    "        \"\"\"\n",
    "        Create a LinearRegression classifier and train it.\n",
    "            \n",
    "            args: pandas dataframe, pandas dataframe, pandas series\n",
    "            \n",
    "            return: numpy array, numpy array\n",
    "        \"\"\"\n",
    "        \n",
    "        lm_model = LinearRegression().fit(x_train, y_train)\n",
    "        \n",
    "        y_predict_train = lm_model.predict(x_train)\n",
    "        y_predict_test = lm_model.predict(x_test)\n",
    "        \n",
    "\n",
    "        return y_predict_train, y_predict_test\n",
    "\n",
    "\n",
    "    def lgTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"\n",
    "        Return accuracy (on the training set) using the accuracy_score method.\n",
    "        Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    "\n",
    "        #predict \n",
    "        y_predict_train = np.where(y_predict_train >= 0.5, 1, 0)\n",
    "        #get the results\n",
    "        train_accuracy = accuracy_score(y_train,y_predict_train)\n",
    "\n",
    "        return train_accuracy\n",
    "    \n",
    "\n",
    "    def lgTestAccuracy(self,y_test,y_predict_test):\n",
    "        \n",
    "        \"\"\"\n",
    "        Return accuracy (on the testing set) using the accuracy_score method.\n",
    "        Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        y_predict_test = np.where(y_predict_test >= 0.5, 1, 0)\n",
    "        test_accuracy = accuracy_score(y_test,y_predict_test)\n",
    "\n",
    "        return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RFClassifier():\n",
    "    \"\"\"\n",
    "    Class for Random Forest Classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    def randomForestClassifier(self,x_train,x_test, y_train):\n",
    "        \"\"\"\n",
    "        Create a RandomForestClassifier and train it. Set Random state to 614.\n",
    "            \n",
    "            args: pandas dataframe, pandas dataframe, pandas series\n",
    "            \n",
    "            return: RandomForestClassifier object, numpy array, numpy array\n",
    "        \"\"\"\n",
    "  \n",
    "        # make the model\n",
    "        rf_clf = RandomForestClassifier(random_state = 614).fit(x_train, y_train)\n",
    "        \n",
    "        #form the model and test on it for first pass combine to steps into one\n",
    "        y_predict_train = rf_clf.predict(x_train)\n",
    "        y_predict_test = rf_clf.predict(x_test)\n",
    "\n",
    "        return rf_clf,y_predict_train, y_predict_test\n",
    "    \n",
    "    \n",
    "    def rfTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"\n",
    "        Return accuracy on the training set using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    "\n",
    "        #how did the model do\n",
    "        train_accuracy = accuracy_score(y_train,y_predict_train)\n",
    "        \n",
    "        return train_accuracy\n",
    "    \n",
    "\n",
    "    def rfTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"\n",
    "        Return accuracy on the test set using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    "        test_accuracy = accuracy_score(y_test,y_predict_test)\n",
    "        \n",
    "        return test_accuracy\n",
    "\n",
    "    \n",
    "### Feature Importance ###\n",
    "    \n",
    "    def rfFeatureImportance(self,rf_clf):\n",
    "        \"\"\"\n",
    "        Determine the feature importance as evaluated by the Random Forest Classifier.\n",
    "            \n",
    "            args: RandomForestClassifier object\n",
    "            \n",
    "            return: float array\n",
    "        \"\"\"\n",
    "\n",
    "        feature_importance = rf_clf.feature_importances_\n",
    "        \n",
    "  \n",
    "        return feature_importance\n",
    "    \n",
    "\n",
    "    def sortedRFFeatureImportanceIndicies(self,rf_clf):\n",
    "        \"\"\"\n",
    "        Sort them in the ascending order and return the feature numbers[0 to ...].\n",
    "   \n",
    "            args: RandomForestClassifier object\n",
    "            \n",
    "            return: int array\n",
    "        \"\"\"\n",
    "        \n",
    "        sorted_indices = np.argsort(rf_clf.feature_importances_)[::] #[::-1] if DESCENDING\n",
    "       \n",
    "    \n",
    "        return sorted_indices\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### Hyper-parameter Tuning ###\n",
    "\n",
    "\n",
    "    def hyperParameterTuning(self,rf_clf,x_train,y_train):\n",
    "        \"\"\"\n",
    "        Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "            \n",
    "            args: RandomForestClassifier object, pandas dataframe, pandas series\n",
    "            \n",
    "            return: GridSearchCV object, float\n",
    "             'n_estimators': [4, 16, 256]\n",
    "             'max_depth': [2, 8, 16]\n",
    "        \"\"\"\n",
    "        \n",
    "        n_estimators = [4, 16, 256]\n",
    "        max_depth = [2, 8, 16]\n",
    "        param_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "        \n",
    "        gscv_rfc = GridSearchCV(estimator = rf_clf, param_grid = param_grid)\n",
    "        gscv_rfc_fit = gscv_rfc.fit(x_train, y_train)\n",
    "        \n",
    "        return gscv_rfc, gscv_rfc_fit\n",
    "    \n",
    "\n",
    "    def bestParams(self,gscv_rfc):\n",
    "        \"\"\"\n",
    "        Get the best params, using .best_params_\n",
    "            \n",
    "            args:  GridSearchCV object\n",
    "            \n",
    "            return: parameter dict \n",
    "        \"\"\"\n",
    "\n",
    "        best_params = gscv_rfc.best_params_\n",
    "       \n",
    "        return best_params\n",
    "    \n",
    "\n",
    "    def bestScore(self,gscv_rfc):\n",
    "        \"\"\"        \n",
    "        Get the best score, using .best_score_.\n",
    "            \n",
    "            args: GridSearchCV object\n",
    "            \n",
    "            return: float\n",
    "        \n",
    "        \"\"\"\n",
    "        best_score = gscv_rfc.best_score_\n",
    "   \n",
    "        return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportVectorMachine():\n",
    "    \n",
    "    \"\"\"\n",
    "    Class for Support Vector Machine Model\n",
    "    \"\"\"\n",
    "    \n",
    "### Pre-process ###\n",
    "\n",
    "    def dataPreProcess(self,x_train,x_test):\n",
    "        \"\"\"\n",
    "        Pre-process the data to standardize it, otherwise the grid search will take much longer.\n",
    "            \n",
    "            args: pandas dataframe, pandas dataframe\n",
    "            \n",
    "            return: pandas dataframe, pandas dataframe\n",
    "        \"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(x_train)\n",
    "        scaled_x_train = scaler.transform(x_train)\n",
    "        scaled_x_test = scaler.transform(x_test)\n",
    "        \n",
    "        return scaled_x_train, scaled_x_test\n",
    "    \n",
    "### Classification ###\n",
    "\n",
    "\n",
    "    def SVCClassifer(self,scaled_x_train,scaled_x_test, y_train):\n",
    "        # TODO: Create a SVC classifier and train it. Set gamma = 'auto'\n",
    "        # args: pandas dataframe, pandas dataframe, pandas series\n",
    "        # return: numpy array, numpy array\n",
    "        # -------------------------------\n",
    "        # ADD CODE HERE\n",
    "       \n",
    "        svm = SVC(gamma='auto').fit(scaled_x_train, y_train)\n",
    "        \n",
    "        y_predict_train = svm.predict(scaled_x_train)\n",
    "        y_predict_test = svm.predict(scaled_x_test)\n",
    "        # -------------------------------\n",
    "        return y_predict_train,y_predict_test\n",
    "    \n",
    "    # points [1]\n",
    "    def SVCTrainAccuracy(self,y_train,y_predict_train):\n",
    "        # TODO: Return accuracy on the training set using the accuracy_score method.\n",
    "        # args: pandas series, numpy array\n",
    "        # return: float \n",
    "        # -------------------------------\n",
    "        # ADD CODE HERE\n",
    "        #train_accuracy = accuracy_score(y_predict_test,y_test)\n",
    "        train_accuracy = accuracy_score(y_train,y_predict_train)\n",
    "       \n",
    "        # -------------------------------\n",
    "        return train_accuracy\n",
    "    \n",
    "    # points [1]\n",
    "    def SVCTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"\n",
    "        Return accuracy on the test set using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float \n",
    "        \"\"\"\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test,y_predict_test)\n",
    "        \n",
    "        return test_accuracy\n",
    "    \n",
    "### Hyper-parameter Tuning ###\n",
    "    \n",
    "\n",
    "    def SVMBestScore(self, scaled_x_train, y_train):\n",
    "        \"\"\"\n",
    "        Tune the hyper-parameters 'C' and 'kernel' using rbf and linear.\n",
    "        Setting n_jobs = -1 and return_train_score = True and gamma = 'auto'\n",
    "        \n",
    "            args: pandas dataframe, pandas series\n",
    "            \n",
    "            return: GridSearchCV object, float\n",
    "        \"\"\"\n",
    "\n",
    "        svm_parameters = {'kernel':('linear', 'rbf'), 'C':[0.01, 0.1, 1.0]}\n",
    "  \n",
    "        svm = SVC(gamma = 'auto')\n",
    "        svm_random = GridSearchCV(estimator = svm, param_grid = svm_parameters,n_jobs = -1,return_train_score = True)\n",
    "        svm_cv = svm_random.fit(scaled_x_train, y_train)\n",
    "\n",
    "        best_score = svm_random.best_score_\n",
    "        \n",
    "        return svm_cv, best_score\n",
    "    \n",
    "\n",
    "    def SVCClassiferParam(self,svm_cv,scaled_x_train,scaled_x_test,y_train):\n",
    "        \"\"\"\n",
    "        Calculate the training and test set accuracy values after hyperparameter tuning and standardization. \n",
    "            \n",
    "            args: GridSearchCV object, pandas dataframe, pandas dataframe, pandas series\n",
    "            \n",
    "            return: numpy series, numpy series\n",
    "        \"\"\"\n",
    "        \n",
    "        y_predict_train = svm_cv.predict(scaled_x_train)\n",
    "        y_predict_test = svm_cv.predict(scaled_x_test)\n",
    "\n",
    "\n",
    "        return y_predict_train,y_predict_test\n",
    "\n",
    "\n",
    "    def svcTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"\n",
    "        Return accuracy (on the training set) using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    " \n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train,y_predict_train)\n",
    "       \n",
    "        return train_accuracy\n",
    "\n",
    "\n",
    "    def svcTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"\n",
    "        Return accuracy (on the test set) using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    " \n",
    "        test_accuracy = accuracy_score(y_test,y_predict_test)\n",
    "        \n",
    "   \n",
    "        return test_accuracy\n",
    "    \n",
    "### Cross Validation Results ###\n",
    "\n",
    "\n",
    "    def SVMRankTestScore(self,svm_cv):\n",
    "        \"\"\"\n",
    "        Return the rank test score for all hyperparameter values that you obtained in SVMBestScore. The \n",
    "        GridSearchCV class holds a ‘cv_results_’ dictionary that allow reports of these metrics easily.\n",
    "        \n",
    "            args: GridSearchCV object \n",
    "            \n",
    "            return: int array\n",
    "        \"\"\"\n",
    "        \n",
    "        rank_test_score= svm_cv.cv_results_['rank_test_score']\n",
    "       \n",
    "\n",
    "        return rank_test_score\n",
    "    \n",
    "\n",
    "    def SVMMeanTestScore(self,svm_cv):\n",
    "        \"\"\"\n",
    "        Return mean test score for all of hyperparameter values that you obtained in SVMBestScore. The \n",
    "        GridSearchCV class holds a ‘cv_results_’ dictionary that allow reports of these metrics easily.\n",
    "            \n",
    "            args: GridSearchCV object\n",
    "            \n",
    "            return: float array\n",
    "        \"\"\"\n",
    "\n",
    "    \n",
    "        mean_test_score= svm_cv.cv_results_['mean_test_score']\n",
    "       \n",
    "        return mean_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAClassifer():\n",
    "    \"\"\"\n",
    "    Class for PCA Classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def pcaClassifer(self,x_data):\n",
    "        \"\"\"\n",
    "        Perform dimensionality reduction of the data using PCA.\n",
    "        Set parameters n_component to 8 and svd_solver to 'full'. Keep other parameters at their default value.\n",
    "        \n",
    "            args: pandas dataframe\n",
    "            \n",
    "            return: pca_object\n",
    "        \"\"\"\n",
    "\n",
    "        pca = PCA(n_components = 8, svd_solver = 'full').fit(x_data)\n",
    "  \n",
    "        return pca\n",
    "    \n",
    "\n",
    "    def pcaExplainedVarianceRatio(self, pca):\n",
    "        \"\"\"\n",
    "        Return percentage of variance explained by each of the selected components\n",
    "        \n",
    "            args: pca_object\n",
    "            \n",
    "            return: float array\n",
    "        \"\"\"\n",
    "\n",
    "        explained_variance_ratio = pca.explained_variance_ratio_\n",
    "        \n",
    "        return explained_variance_ratio\n",
    "\n",
    "    def pcaSingularValues(self, pca):\n",
    "        \"\"\"\n",
    "        Return the singular values corresponding to each of the selected components.\n",
    "            \n",
    "            args: pca_object\n",
    "            \n",
    "            return: float array\n",
    "        \"\"\"\n",
    "\n",
    "        singular_values = pca.singular_values_\n",
    "       \n",
    "\n",
    "        return singular_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataAllocation Function Executed\n",
      "trainSets Function Executed\n",
      "\n",
      "\n",
      "linearClassifer Function Executed\n",
      "Linear Regression Train Accuracy:  0.7839851024208566\n",
      "Linear Regression Test Accuracy:  0.7316017316017316\n",
      "\n",
      "\n",
      "randomForestClassifier Function Executed\n",
      "Random Forest Train Accuracy:  1.0\n",
      "Random Forest Test Accuracy:  0.7316017316017316\n",
      "Random Forest Feature Importance:  [0.07481604 0.25521095 0.08551354 0.07373347 0.0754602  0.1630978\n",
      " 0.12729624 0.14487176]\n",
      "Random Forest Sorted Feature Importance:  [3 0 4 2 6 7 5 1]\n",
      "HyperParameterTuning Function Executed\n",
      "Random Forest Best Parameters:  {'max_depth': 8, 'n_estimators': 256}\n",
      "Random Forest Best Score:  0.7858255451713395\n",
      "\n",
      "\n",
      "dataPreProcess Function Executed\n",
      "SVCClassifer Function Executed\n",
      "Support Vector Machine Trian Accuracy:  0.8324022346368715\n",
      "Support Vector Machine Test Accuracy:  0.7272727272727273\n",
      "Support Vector Machine Best Score:  0.7820526133610246\n",
      "SVCClassiferParam Function Executed\n",
      "Support Vector Machine Trian Accuracy:  0.7877094972067039\n",
      "Support Vector Machine Test Accuracy:  0.7575757575757576\n",
      "Support Vector Machine Rank Test Score:  [4 6 2 5 1 3]\n",
      "Support Vector Machine Mean Test Score:  [0.77826237 0.63501211 0.782018   0.76341295 0.78205261 0.78033922]\n",
      "\n",
      "\n",
      "pcaClassifer Function Executed\n",
      "PCA Explained Variance Ratio:  [8.88546635e-01 6.15907837e-02 2.57901189e-02 1.30861374e-02\n",
      " 7.44093864e-03 3.02614919e-03 5.12444875e-04 6.79264301e-06]\n",
      "PCA Singular Values:  [3212.6611207   845.82919167  547.33280231  389.87962763  293.9941346\n",
      "  187.48648707   77.15221185    8.88268374]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tests.dataTest(Data)\n",
    "    print(\"\\n\")\n",
    "    tests.linearTest(Data,LinearRegressionModel)\n",
    "    print(\"\\n\")\n",
    "    tests.RandomForestTest(Data,RFClassifier)\n",
    "    print(\"\\n\")\n",
    "    best_score_svm = tests.SupportVectorMachineTest(Data,SupportVectorMachine)\n",
    "    print(\"\\n\")\n",
    "    tests.PCATest(Data,PCAClassifer)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Analysis\n",
    "Who did best? As the below table and graph illustrates, the Random Forest performed the best onthe test data. Principal Component Analysis (PCA) Dimensionality reduction is an essential task in many data analysis exercises, and it involves projecting the data to a lower-dimensional space using Singular Value Decomposition. This can be done in conjunction with the tested classifiers to get the percentage of variance explained by each of the selected components and thereofre, if one is limited to time or resources, use only the imporant features for training. This coudl alter the results, if for example, one model cannot be used because it is resource heavy, but then PCA allows it to be used, it may produce the best results and had not been used wihtout PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Classifier</th>\n",
       "      <td>0.731602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.785826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM Classifier</th>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Accuracy\n",
       "Linear Classifier  0.731602\n",
       "Random Forest      0.785826\n",
       "SVM Classifier     0.757576"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = [0.7316017316017316,0.7858255451713395,0.7575757575757576]\n",
    "models = ['Linear Classifier','Random Forest','SVM Classifier']\n",
    "df = pd.DataFrame(list(zip(models, results)),columns =['Models', 'Accuracy'])\n",
    "\n",
    "df.index = list(df[\"Models\"])\n",
    "df = df.drop(columns=['Models'])\n",
    "\n",
    "df[['Accuracy']].plot.bar(ylim = (.70,1))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
