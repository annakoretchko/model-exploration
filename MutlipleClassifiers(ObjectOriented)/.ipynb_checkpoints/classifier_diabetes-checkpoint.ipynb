{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different Classifiers, Hyertuning Methods, and Speed on Diabetes Classification\n",
    "\n",
    "1. Linear Regression Classifer\n",
    "    1. Classification\n",
    "2. Random Forest Classifier\n",
    "    1. Classification\n",
    "    2. Feature Importance\n",
    "    3. Hyper-Parameter Tuning\n",
    "3. Support Vector Machine\n",
    "    1. Preprocesing\n",
    "    2. Classification\n",
    "    3. Hyper-Parameter Tuning\n",
    "    4. Cross-Validation Results\n",
    "4. Principal Component Analysis\n",
    "    1. Dimensionality reduction is an essential task in many data analysis exercises, and it involves projecting the data to a lower-dimensional space using Singular Value Decomposition. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# !{sys.executable} -m pip uninstall networkx\n",
    "# !{sys.executable} -m pip install pandas==1.1.0\n",
    "#!{sys.executable} -m pip install networkx==2.4\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "print(pd.__version__)\n",
    "import tests as tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \"\"\"\n",
    "    Class for the Data for the models\n",
    "    \"\"\"\n",
    "    def dataAllocation(self,path):\n",
    "        \n",
    "        \"\"\"\n",
    "        Separate out the x_data and y_data and return each\n",
    "        \n",
    "            args: string path for .csv file\n",
    "            \n",
    "            return: pandas dataframe, pandas dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        data = pd.read_csv(path)\n",
    "        x_data = data.loc[:,data.columns != \"y\"].to_numpy()\n",
    "        y_data = data.loc[:,\"y\"].to_numpy()\n",
    "        \n",
    "        return x_data,y_data\n",
    "    \n",
    "    def trainSets(self,x_data,y_data):\n",
    "        \"\"\"\n",
    "        Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test.\n",
    "        Use the train_test_split method in sklearn with the parameter 'shuffle' set to true and the 'random_state' set to 614.\n",
    "            \n",
    "            args: pandas dataframe, pandas dataframe\n",
    "            \n",
    "            return: pandas dataframe, pandas dataframe, pandas series, pandas series\n",
    "        \"\"\"\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.3, random_state = 614, shuffle=True)\n",
    "        y_train = pd.Series(y_train) \n",
    "        y_test = pd.Series(y_test) \n",
    "\n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel():\n",
    "    \"\"\"\n",
    "    Class for Linear Regression Model\n",
    "    \"\"\"\n",
    "    def linearClassifer(self,x_train, x_test, y_train):\n",
    "        \"\"\"\n",
    "        Create a LinearRegression classifier and train it.\n",
    "            \n",
    "            args: pandas dataframe, pandas dataframe, pandas series\n",
    "            \n",
    "            return: numpy array, numpy array\n",
    "        \"\"\"\n",
    "        \n",
    "        lm_model = LinearRegression().fit(x_train, y_train)\n",
    "        \n",
    "        y_predict_train = lm_model.predict(x_train)\n",
    "        y_predict_test = lm_model.predict(x_test)\n",
    "        \n",
    "\n",
    "        return y_predict_train, y_predict_test\n",
    "\n",
    "\n",
    "    def lgTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"\n",
    "        Return accuracy (on the training set) using the accuracy_score method.\n",
    "        Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    "\n",
    "        #predict \n",
    "        y_predict_train = np.where(y_predict_train >= 0.5, 1, 0)\n",
    "        #get the results\n",
    "        train_accuracy = accuracy_score(y_train,y_predict_train)\n",
    "\n",
    "        return train_accuracy\n",
    "    \n",
    "\n",
    "    def lgTestAccuracy(self,y_test,y_predict_test):\n",
    "        \n",
    "        \"\"\"\n",
    "        Return accuracy (on the testing set) using the accuracy_score method.\n",
    "        Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        y_predict_test = np.where(y_predict_test >= 0.5, 1, 0)\n",
    "        test_accuracy = accuracy_score(y_test,y_predict_test)\n",
    "\n",
    "        return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RFClassifier():\n",
    "    \"\"\"\n",
    "    Class for Random Forest Classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    def randomForestClassifier(self,x_train,x_test, y_train):\n",
    "        \"\"\"\n",
    "        Create a RandomForestClassifier and train it. Set Random state to 614.\n",
    "            \n",
    "            args: pandas dataframe, pandas dataframe, pandas series\n",
    "            \n",
    "            return: RandomForestClassifier object, numpy array, numpy array\n",
    "        \"\"\"\n",
    "  \n",
    "        # make the model\n",
    "        rf_clf = RandomForestClassifier(random_state = 614).fit(x_train, y_train)\n",
    "        \n",
    "        #form the model and test on it for first pass combine to steps into one\n",
    "        y_predict_train = rf_clf.predict(x_train)\n",
    "        y_predict_test = rf_clf.predict(x_test)\n",
    "\n",
    "        return rf_clf,y_predict_train, y_predict_test\n",
    "    \n",
    "    \n",
    "    def rfTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"\n",
    "        Return accuracy on the training set using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    "\n",
    "        #how did the model do\n",
    "        train_accuracy = accuracy_score(y_train,y_predict_train)\n",
    "        \n",
    "        return train_accuracy\n",
    "    \n",
    "\n",
    "    def rfTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"\n",
    "        Return accuracy on the test set using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    "        test_accuracy = accuracy_score(y_test,y_predict_test)\n",
    "        \n",
    "        return test_accuracy\n",
    "\n",
    "    \n",
    "### Feature Importance ###\n",
    "    \n",
    "    def rfFeatureImportance(self,rf_clf):\n",
    "        \"\"\"\n",
    "        Determine the feature importance as evaluated by the Random Forest Classifier.\n",
    "            \n",
    "            args: RandomForestClassifier object\n",
    "            \n",
    "            return: float array\n",
    "        \"\"\"\n",
    "\n",
    "        feature_importance = rf_clf.feature_importances_\n",
    "        \n",
    "  \n",
    "        return feature_importance\n",
    "    \n",
    "\n",
    "    def sortedRFFeatureImportanceIndicies(self,rf_clf):\n",
    "        \"\"\"\n",
    "        Sort them in the ascending order and return the feature numbers[0 to ...].\n",
    "   \n",
    "            args: RandomForestClassifier object\n",
    "            \n",
    "            return: int array\n",
    "        \"\"\"\n",
    "        \n",
    "        sorted_indices = np.argsort(rf_clf.feature_importances_)[::] #[::-1] if DESCENDING\n",
    "       \n",
    "    \n",
    "        return sorted_indices\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### Hyper-parameter Tuning ###\n",
    "\n",
    "\n",
    "    def hyperParameterTuning(self,rf_clf,x_train,y_train):\n",
    "        \"\"\"\n",
    "        Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "            \n",
    "            args: RandomForestClassifier object, pandas dataframe, pandas series\n",
    "            \n",
    "            return: GridSearchCV object, float\n",
    "             'n_estimators': [4, 16, 256]\n",
    "             'max_depth': [2, 8, 16]\n",
    "        \"\"\"\n",
    "        \n",
    "        n_estimators = [4, 16, 256]\n",
    "        max_depth = [2, 8, 16]\n",
    "        param_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "        \n",
    "        gscv_rfc = GridSearchCV(estimator = rf_clf, param_grid = param_grid)\n",
    "        gscv_rfc_fit = gscv_rfc.fit(x_train, y_train)\n",
    "        \n",
    "        return gscv_rfc, gscv_rfc_fit\n",
    "    \n",
    "\n",
    "    def bestParams(self,gscv_rfc):\n",
    "        \"\"\"\n",
    "        Get the best params, using .best_params_\n",
    "            \n",
    "            args:  GridSearchCV object\n",
    "            \n",
    "            return: parameter dict \n",
    "        \"\"\"\n",
    "\n",
    "        best_params = gscv_rfc.best_params_\n",
    "       \n",
    "        return best_params\n",
    "    \n",
    "\n",
    "    def bestScore(self,gscv_rfc):\n",
    "        \"\"\"        \n",
    "        Get the best score, using .best_score_.\n",
    "            \n",
    "            args: GridSearchCV object\n",
    "            \n",
    "            return: float\n",
    "        \n",
    "        \"\"\"\n",
    "        best_score = gscv_rfc.best_score_\n",
    "   \n",
    "        return best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportVectorMachine():\n",
    "    \n",
    "    \"\"\"\n",
    "    Class for Support Vector Machine Model\n",
    "    \"\"\"\n",
    "    \n",
    "### Pre-process ###\n",
    "\n",
    "    def dataPreProcess(self,x_train,x_test):\n",
    "        \"\"\"\n",
    "        Pre-process the data to standardize it, otherwise the grid search will take much longer.\n",
    "            \n",
    "            args: pandas dataframe, pandas dataframe\n",
    "            \n",
    "            return: pandas dataframe, pandas dataframe\n",
    "        \"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(x_train)\n",
    "        scaled_x_train = scaler.transform(x_train)\n",
    "        scaled_x_test = scaler.transform(x_test)\n",
    "        \n",
    "        return scaled_x_train, scaled_x_test\n",
    "    \n",
    "### Classification ###\n",
    "\n",
    "\n",
    "    def SVCClassifer(self,scaled_x_train,scaled_x_test, y_train):\n",
    "        # TODO: Create a SVC classifier and train it. Set gamma = 'auto'\n",
    "        # args: pandas dataframe, pandas dataframe, pandas series\n",
    "        # return: numpy array, numpy array\n",
    "        # -------------------------------\n",
    "        # ADD CODE HERE\n",
    "       \n",
    "        svm = SVC(gamma='auto').fit(scaled_x_train, y_train)\n",
    "        \n",
    "        y_predict_train = svm.predict(scaled_x_train)\n",
    "        y_predict_test = svm.predict(scaled_x_test)\n",
    "        # -------------------------------\n",
    "        return y_predict_train,y_predict_test\n",
    "    \n",
    "    # points [1]\n",
    "    def SVCTrainAccuracy(self,y_train,y_predict_train):\n",
    "        # TODO: Return accuracy on the training set using the accuracy_score method.\n",
    "        # args: pandas series, numpy array\n",
    "        # return: float \n",
    "        # -------------------------------\n",
    "        # ADD CODE HERE\n",
    "        #train_accuracy = accuracy_score(y_predict_test,y_test)\n",
    "        train_accuracy = accuracy_score(y_train,y_predict_train)\n",
    "       \n",
    "        # -------------------------------\n",
    "        return train_accuracy\n",
    "    \n",
    "    # points [1]\n",
    "    def SVCTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"\n",
    "        Return accuracy on the test set using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float \n",
    "        \"\"\"\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test,y_predict_test)\n",
    "        \n",
    "        return test_accuracy\n",
    "    \n",
    "### Hyper-parameter Tuning ###\n",
    "    \n",
    "\n",
    "    def SVMBestScore(self, scaled_x_train, y_train):\n",
    "        \"\"\"\n",
    "        Tune the hyper-parameters 'C' and 'kernel' using rbf and linear.\n",
    "        Setting n_jobs = -1 and return_train_score = True and gamma = 'auto'\n",
    "        \n",
    "            args: pandas dataframe, pandas series\n",
    "            \n",
    "            return: GridSearchCV object, float\n",
    "        \"\"\"\n",
    "\n",
    "        svm_parameters = {'kernel':('linear', 'rbf'), 'C':[0.01, 0.1, 1.0]}\n",
    "  \n",
    "        svm = SVC(gamma = 'auto')\n",
    "        svm_random = GridSearchCV(estimator = svm, param_grid = svm_parameters,n_jobs = -1,return_train_score = True)\n",
    "        svm_cv = svm_random.fit(scaled_x_train, y_train)\n",
    "\n",
    "        best_score = svm_random.best_score_\n",
    "        \n",
    "        return svm_cv, best_score\n",
    "    \n",
    "\n",
    "    def SVCClassiferParam(self,svm_cv,scaled_x_train,scaled_x_test,y_train):\n",
    "        \"\"\"\n",
    "        Calculate the training and test set accuracy values after hyperparameter tuning and standardization. \n",
    "            \n",
    "            args: GridSearchCV object, pandas dataframe, pandas dataframe, pandas series\n",
    "            \n",
    "            return: numpy series, numpy series\n",
    "        \"\"\"\n",
    "        \n",
    "        y_predict_train = svm_cv.predict(scaled_x_train)\n",
    "        y_predict_test = svm_cv.predict(scaled_x_test)\n",
    "\n",
    "\n",
    "        return y_predict_train,y_predict_test\n",
    "\n",
    "\n",
    "    def svcTrainAccuracy(self,y_train,y_predict_train):\n",
    "        \"\"\"\n",
    "        Return accuracy (on the training set) using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    " \n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train,y_predict_train)\n",
    "       \n",
    "        return train_accuracy\n",
    "\n",
    "\n",
    "    def svcTestAccuracy(self,y_test,y_predict_test):\n",
    "        \"\"\"\n",
    "        Return accuracy (on the test set) using the accuracy_score method.\n",
    "            \n",
    "            args: pandas series, numpy array\n",
    "            \n",
    "            return: float\n",
    "        \"\"\"\n",
    " \n",
    "        test_accuracy = accuracy_score(y_test,y_predict_test)\n",
    "        \n",
    "   \n",
    "        return test_accuracy\n",
    "    \n",
    "### Cross Validation Results ###\n",
    "\n",
    "\n",
    "    def SVMRankTestScore(self,svm_cv):\n",
    "        \"\"\"\n",
    "        Return the rank test score for all hyperparameter values that you obtained in SVMBestScore. The \n",
    "        GridSearchCV class holds a ‘cv_results_’ dictionary that allow reports of these metrics easily.\n",
    "        \n",
    "            args: GridSearchCV object \n",
    "            \n",
    "            return: int array\n",
    "        \"\"\"\n",
    "        \n",
    "        rank_test_score= svm_cv.cv_results_['rank_test_score']\n",
    "       \n",
    "\n",
    "        return rank_test_score\n",
    "    \n",
    "\n",
    "    def SVMMeanTestScore(self,svm_cv):\n",
    "        \"\"\"\n",
    "        Return mean test score for all of hyperparameter values that you obtained in SVMBestScore. The \n",
    "        GridSearchCV class holds a ‘cv_results_’ dictionary that allow reports of these metrics easily.\n",
    "            \n",
    "            args: GridSearchCV object\n",
    "            \n",
    "            return: float array\n",
    "        \"\"\"\n",
    "\n",
    "    \n",
    "        mean_test_score= svm_cv.cv_results_['mean_test_score']\n",
    "       \n",
    "        return mean_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAClassifer():\n",
    "    \"\"\"\n",
    "    Class for PCA Classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def pcaClassifer(self,x_data):\n",
    "        \"\"\"\n",
    "        Perform dimensionality reduction of the data using PCA.\n",
    "        Set parameters n_component to 8 and svd_solver to 'full'. Keep other parameters at their default value.\n",
    "        \n",
    "            args: pandas dataframe\n",
    "            \n",
    "            return: pca_object\n",
    "        \"\"\"\n",
    "\n",
    "        pca = PCA(n_components = 8, svd_solver = 'full').fit(x_data)\n",
    "  \n",
    "        return pca\n",
    "    \n",
    "\n",
    "    def pcaExplainedVarianceRatio(self, pca):\n",
    "        \"\"\"\n",
    "        Return percentage of variance explained by each of the selected components\n",
    "        \n",
    "            args: pca_object\n",
    "            \n",
    "            return: float array\n",
    "        \"\"\"\n",
    "\n",
    "        explained_variance_ratio = pca.explained_variance_ratio_\n",
    "        \n",
    "        return explained_variance_ratio\n",
    "\n",
    "    def pcaSingularValues(self, pca):\n",
    "        \"\"\"\n",
    "        Return the singular values corresponding to each of the selected components.\n",
    "            \n",
    "            args: pca_object\n",
    "            \n",
    "            return: float array\n",
    "        \"\"\"\n",
    "\n",
    "        singular_values = pca.singular_values_\n",
    "       \n",
    "\n",
    "        return singular_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataAllocation Function Executed\n",
      "trainSets Function Executed\n",
      "\n",
      "\n",
      "linearClassifer Function Executed\n",
      "Linear Regression Train Accuracy:  0.7839851024208566\n",
      "Linear Regression Test Accuracy:  0.7316017316017316\n",
      "\n",
      "\n",
      "randomForestClassifier Function Executed\n",
      "Random Forest Train Accuracy:  1.0\n",
      "Random Forest Test Accuracy:  0.7316017316017316\n",
      "Random Forest Feature Importance:  [0.07481604 0.25521095 0.08551354 0.07373347 0.0754602  0.1630978\n",
      " 0.12729624 0.14487176]\n",
      "Random Forest Sorted Feature Importance:  [3 0 4 2 6 7 5 1]\n",
      "HyperParameterTuning Function Executed\n",
      "Random Forest Best Parameters:  {'max_depth': 8, 'n_estimators': 256}\n",
      "Random Forest Best Score:  0.7858255451713395\n",
      "\n",
      "\n",
      "dataPreProcess Function Executed\n",
      "SVCClassifer Function Executed\n",
      "Support Vector Machine Trian Accuracy:  0.8324022346368715\n",
      "Support Vector Machine Test Accuracy:  0.7272727272727273\n",
      "Support Vector Machine Best Score:  0.7820526133610246\n",
      "SVCClassiferParam Function Executed\n",
      "Support Vector Machine Trian Accuracy:  0.7877094972067039\n",
      "Support Vector Machine Test Accuracy:  0.7575757575757576\n",
      "Support Vector Machine Rank Test Score:  [4 6 2 5 1 3]\n",
      "Support Vector Machine Mean Test Score:  [0.77826237 0.63501211 0.782018   0.76341295 0.78205261 0.78033922]\n",
      "\n",
      "\n",
      "pcaClassifer Function Executed\n",
      "PCA Explained Variance Ratio:  [8.88546635e-01 6.15907837e-02 2.57901189e-02 1.30861374e-02\n",
      " 7.44093864e-03 3.02614919e-03 5.12444875e-04 6.79264301e-06]\n",
      "PCA Singular Values:  [3212.6611207   845.82919167  547.33280231  389.87962763  293.9941346\n",
      "  187.48648707   77.15221185    8.88268374]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tests.dataTest(Data)\n",
    "    print(\"\\n\")\n",
    "    tests.linearTest(Data,LinearRegressionModel)\n",
    "    print(\"\\n\")\n",
    "    tests.RandomForestTest(Data,RFClassifier)\n",
    "    print(\"\\n\")\n",
    "    best_score_svm = tests.SupportVectorMachineTest(Data,SupportVectorMachine)\n",
    "    print(\"\\n\")\n",
    "    tests.PCATest(Data,PCAClassifer)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7820526133610246\n"
     ]
    }
   ],
   "source": [
    "def get_all_accuracy():\n",
    "    dataset = Data()\n",
    "    svm = SupportVectorMachine()\n",
    "    data = '../data/pima-indians-diabetes.csv'\n",
    "    x_data,y_data = dataset.dataAllocation(data)\n",
    "    x_train, x_test, y_train, y_test = dataset.trainSets(x_data,y_data)\n",
    "    scaled_x_train, scaled_x_test = svm.dataPreProcess(x_train,x_test)\n",
    "    y_predict_train,y_predict_test = svm.SVCClassifer(scaled_x_train,scaled_x_test, y_train)\n",
    "    svm_cv, best_score_svm = svm.SVMBestScore(scaled_x_train, y_train)\n",
    "    print(best_score)\n",
    "    \n",
    "    return best_score_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
